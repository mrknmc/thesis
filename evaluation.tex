\chapter{Evaluation}

In this chapter we evaluate Storm-MC. We describe the metrics used to evaluate performance of Storm-MC (\ref{sec:metrics}), list the configuration used for benchmarking (\ref{sec:system_conf}), compare Storm-MC to Apache Storm executing in local mode on a set of different topologies (\ref{sec:performance}), and finally talk about challenges encountered while designing Storm-MC (\ref{sec:challenges}).

\section{Evaluation Metrics}
\label{sec:metrics}

The system was evaluated on the following metrics:

\begin{description}
	\item[Throughput] \hfill \\
	The number of tuples processed by every component in the given time of the topology is recorded.
	\item[CPU Utilisation] \hfill \\
	Usage of CPU is recorded every \textbf{x} seconds throughout execution and the average is computed.
	\item[Memory Usage] \hfill \\
	Main memory usage is recorded every \textbf{x} seconds throughout execution and the average is computed.
\end{description}

\section{System Configuration}
\label{sec:system_conf}

\subsection{Software Setup}

All performance benchmarks were ran using the following software packages:

\begin{itemize}
	\item Apache Storm version 0.9.2
	\item Storm-MC version 0.1.6
	\item A fork of IBM Storm Email Benchmarks version 0.1.10
	\item Storm-benchmark version 0.1.0
\end{itemize}

The Apache Storm source code had to be adapted to include a workaround for a deadlock bug present in version 0.9.2. This bug caused a topology to exit with threads left in Zombie state under certain conditions. This prevented Storm from logging the benchmark metrics after execution. Hence a workaround was added so the results were logged.

Version 0.1.6 is the latest version of Storm-MC as of this moment. The first release was version 0.1.0 which was production-ready but since then there were 6 minor versions fixing bugs as they were discovered during testing.

IBM open sourced a suite of benchmarks which they used to compare Apache Storm to their real-time stream system IBM Infosphere Streams \citep{InfoSphereStreams}. These benchmarks were adapted and used to benchmark Storm-MC against Apache Storm.

Finally, a number of spout and bolt components were used from the storm-benchmark project which Apache Storm developers use to benchmark Storm.

Since Storm-MC reuses package names from Apache Storm, the same benchmark is directly executable by both libraries. This saved a lot of time and furthermore there is no need to maintain two benchmarks suites.

\todo{Go into more detail which components were re-used and where?}

\subsection{Hardware Setup}

The machine used for benchmarking is the Informatics Student Compute server (\texttt{student.compute.inf.ed.ac.uk}). The server has the following hardware components:

\begin{description}
	\item[Processor: Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} E5-2690 v2 @ 3.00 GHz] \hfill \\
	The machine has two sockets with the same processor each. The processor has 10 physical cores with Hyper-Threading Technology which means it can handle up to 20 threads in parallel. Thus with two sockets, there is potential to execute up to 40 threads in parallel.
	\item[Main Memory] \hfill \\
	The machine has 378 GB of main memory. Since data stream processing uses windows to store only up to a certain amount of memory this was more than enough to conduct the benchmarks.
\end{description}

\subsection{Storm Configuration}

As mentioned before, when submitting a topology the programmer needs to submit a configuration file as well. To ensure that the performance difference between Apache Storm and Storm-MC was not caused by different configuration, the default configuration file from Storm 0.9.2 was used to benchmark both projects.

%Most notably, the size of the ring buffer used by executors (\texttt{topology.executor.receive.buffer.size}) was set to 1024 and the wait strategy employed by executors when there are no tuples to pick up (\texttt{topology.disruptor.wait.strategy}) was set to \texttt{BlockingWaitStrategy}.

\section{Results}
\label{sec:performance}

To assess performance of Storm-MC, 4 different benchmarks were executed, each with a different focus. The benchmarks were executed for a constant period of time (five minutes) after which the system was killed and metrics were collected. To avoid any performance differences caused by varying amounts of heap memory required by the tested systems, the programs were run with the following flag: \texttt{-Xmx10240M}. This flag sets the maximum amount of heap memory used by the JVM to 10 GB which was more than enough for all benchmarks.

The parallelism of components was varied from one to six and average CPU utilisation and resident memory size were recorded by the Unix \texttt{top} program \citep{UnixTop}. Maximum CPU utilisation with 40 threads is 4,000\%. Resident memory size is the amount of non-swapped physical memory a task has used. This metric can be deceiving as it depends on how OS manages memory but it is the only fairly reliable memory metric reported by \texttt{top} that can be used for Java programs.

\subsection{WordCount Topology}

The first topology tested for performance is a variant of the aforementioned WordCount topology. This topology has a spout \texttt{FileReadSpout} generating random sentences, which sends messages to a \texttt{SplitSentenceBolt} bolt which splits the sentences on whitespace and sends individual words to a \texttt{CountBolt} which counts word frequencies. Recall, that this topology is shown graphically in Figure \ref{fig:wordcount_topology}. Since the components do not store any data in memory or make any I/O calls this topology is mostly CPU-bound.

The number of tuples processed by each component in Storm-MC and Apache Storm is shown in tables \ref{table:storm_mc_wordcount} and \ref{table:storm_wordcount}, respectively. As can be seen from the tables, not only was CPU utilisation in Storm-MC lower, Storm-MC often processed more than twice as many tuples per component than Apache Storm.  The number of tuples processed by \texttt{CountBolt}, the last component of the topology, is also show in Figure \ref{fig:countbolt-plot}. Since this topology is serial, the number of tuples processed by \texttt{CountBolt} is a good indicator of total throughput.

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccccl@{}}
    \textbf{Parallelism} & \textbf{FileReadSpout} & \textbf{SplitSentenceBolt} & \textbf{CountBolt} & \textbf{CPU Utilisation} & \textbf{Resident Size} \\ \toprule
    1 & {25,767,502} & {25,767,502} & {225,815,174} & {217.9\%} & {690.8M} \\
    2 & {34,403,678} & {34,403,127} & {301,493,247} & {414.6\%} & {759.1M} \\
    3 & {45,731,188} & {45,732,988} & {400,767,999} & {611.5\%} & {798.4M} \\
    4 & {52,285,327} & {52,283,540} & {458,187,555} & {805.5\%} & {804.1M} \\
	5 & {55,326,941} & {55,325,167} & {484,844,652} & {998.7\%} & {806.0M} \\
	6 & {56,747,319} & {56,744,629} & {497,285,149} & {1,195.3\%} & {824.8M} \\
	10 & {40,341,798} & {40,336,962} & {353,490,567} & {1,967.4\%} & {2.7G} \\
%	20 & {55,442,981} & {55,430,441} & {485,763,957} & {3161.5\%} & {2.1} \\
\end{tabular}
\caption{Storm-MC: Tuples processed per component in WordCount Topology.}
\label{table:storm_mc_wordcount}
\end{adjustwidth}
\end{table}

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccccl@{}}
    \textbf{Parallelism} & \textbf{FileReadSpout} & \textbf{SplitSentenceBolt} & \textbf{CountBolt} & \textbf{CPU Utilisation} & \textbf{Resident Size} \\ \toprule
    1 & {12,583,377} & {12,579,132} & {110,233,966} & {294.5\%} & {2.2G} \\
    2 & {16,800,475} & {16,796,695} & {147,194,709} & {481.7\%} & {2.8G} \\
    3 & {22,120,695} & {22,107,696} & {193,735,106} & {687.1\%} & {2.6G} \\
    4 & {20,720,637} & {20,711,756} & {181,500,586} & {895.3\%} & {2.6G} \\
	5 & {17,177,688} & {17,164,209} & {150,412,037} & {1,129.3\%} & {2.5G} \\
	6 & {17,402,418} & {17,388,691} & {152,374,303} & {1,342.1\%} & {2.3G} \\
	10 & {12,229,523} & {12,211,100} & {107,002,632} & {2,136.7\%} & {2.8G} \\
%	20 & {19,950,916} & {19,892,159} & {174,299,740} & {2,813.7\%} & {3.5G} \\
\end{tabular}
\caption{Apache Storm: Tuples processed per component in WordCount Topology.}
\label{table:storm_wordcount}
\end{adjustwidth}
\end{table}

<<countbolt-plot, echo=FALSE, cache=FALSE, fig.cap="Tuples processed by CountBolt in Storm-MC and Apache Storm", fig.align="center", fig.pos="!htb", fig.height=3.5>>=
@

Furthermore, it can be seen that after the parallelism is increased beyond three the throughput of Apache Storm tails off and starts going down. This can be attributed to the number of threads ran by Apache Storm. For Storm-MC this tailing off occurs with parallelism of six where the overhead of multiple producers possibly trying to publish to the same queue becomes apparent. Moreover, with parallelism set to 6, Storm-MC executes with 20 threads which is close to the number of physical cores of the machine. However, it should be noted that even with parallelism equal to 10, Storm-MC still processes more than three times as many tuples as Storm.

<<threads-plot, echo=FALSE, cache=FALSE, fig.cap="Number of threads used by Storm and Storm-MC", fig.align="center", fig.pos="!htb", fig.height=3.5>>=
@

The number of threads required to execute a topology is a linear function of the parallelism for both Storm and Storm-MC. However, as shown in Figure \ref{fig:threads-plot}, the number of threads required by Storm increases more rapidly than Storm-MC. For example, with parallelism set to 10, Storm creates 109 threads whereas Storm-MC creates only 32. More formally, the number of threads required by both systems can be expressed as:

\begin{figure}[!htb]
\begin{eqnarray*}
	49 \ + \ 2 \times \sum\limits_{c}^{components} parallelism(c) && \text{ for Apache Storm.} \\
	2 \ + \ \sum\limits_{c}^{components} parallelism(c) && \text{ for Storm-MC.}
\end{eqnarray*}
\caption{Number of threads used by Storm and Storm-MC.}
\end{figure}

\textbf{N.B.}\@\xspace: This is a general formula that applies to all topologies, not just WordCount.

Of note, the resident size used by Storm-MC is also less than half of the resident size used by Storm for cases with parallelism less than 10.

\subsection{Enron Topology}

Next, Enron topology from the IBM benchmarks was tested for performance. In this topology, serialised emails from the Enron email dataset are read from a file by a \texttt{ReadEmailsDecompressSpout} spout. They are then deserialised by \texttt{AvroDeserializeBolt} bolt, filtered by \texttt{NewFilterBolt} bolt, modified by \texttt{ModifyBolt} bolt, and finally metrics are recorded by a \texttt{NewMetricsBolt} bolt. Additionally, the \texttt{NewMetricsBolt} bolt sends its local average email throughput to a global (excluded from the parallelism setting) \texttt{GlobalMetricsBolt} bolt every four seconds. This bolt then records the global average email throughput.

Similarly to the WordCount topology, this topology is serial in nature. However, whereas the spout in  WordCount topology keeps a small number of sentences in memory, the Enron topology has a spout that produces tuples by reading from a file. Thus, this benchmark is mostly I/O-bound. The average email throughput in Storm-MC and Apache Storm is shown in tables \ref{table:storm_mc_enron} and \ref{table:storm_enron}, respectively. 

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccl@{}}
    \textbf{Parallelism} & \textbf{Emails Processed} & \textbf{CPU Utilisation} & \textbf{Resident Size} \\ \toprule
    1 & {3,285,742} & {297.7\%} & {806.8M} \\
    2 & {6,696,612} & {482.1\%} & {756.1M} \\
    3 & {8,493,772} & {729.5\%} & {341.4M} \\
    4 & {11,102,969} & {1036.9\%} & {326.0M} \\
    5 & {12,630,475} & {1311.0\%} & {260.8M} \\
    6 & {14,082,501} & {1590.3\%} & {334.0M} \\
\end{tabular}
\caption{Storm-MC: Email Throughput in Enron Topology.}
\label{table:storm_mc_enron}
\end{adjustwidth}
\end{table}

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccl@{}}
    \textbf{Parallelism} & \textbf{Emails Processed} & \textbf{CPU Utilisation} & \textbf{Resident Size} \\ \toprule
    1 & {2,943,709} & {406.6\%} & {1.94G} \\
    2 & {4,832,874} & {945.1\%} & {2.93G} \\
    3 & {5,623,028} & {1,427.4\%} & {3.32G} \\
    4 & {6,238,395} & {1,891.2\%} & {3.56G} \\
    5 & {6,105,155} & {2167.4\%} & {3.65G} \\
    6 & {7,242,298} & {2388.6\%} & {4.09G} \\
\end{tabular}
\caption{Apache Storm: Email Throughput in Enron Topology.}
\label{table:storm_enron}
\end{adjustwidth}
\end{table}

<<enron-plot, echo=FALSE, cache=FALSE, fig.cap="Global Email Throughput over time", fig.align="center", fig.pos="!htb", fig.height=6.5>>=
@

As can be seen from the tables, the difference in throughput in Enron Topology is less staggering than in WordCount. This is due to the fact that the throughput is limited by the file reads of the spout. However, as the parallelism increases the improvement in throughput of Storm-MC becomes more apparent as shown in Figure \ref{fig:enron-plot}. This figure also shows that the throughput is fairly volatile. This is due to the fact that the file is loaded into main memory in chunks and hence the throughput drops when the spout is trying to read from a file in between the loads. As before, the resident size used by Storm-MC is significantly lower than that of Storm.

\subsection{RollingSort Topology}

The RollingSort topology was ported over from the aforementioned storm-benchmark project. This topology only includes one spout sending tuples to one bolt. The \texttt{RandomMessageSpout} spout produces hundred character-long strings of random digits from zero to eight. The \texttt{SortBolt} bolt then stores a rolling window of hundred of such messages and sorts them every 10 seconds. This benchmark is considered to be memory-bound: the bolt stores a window of tuples in memory and performs a non-linear time sort. The results of running this benchmark on Storm-MC and Apache Storm can be seen in tables \ref{table:storm_mc_rolling} and \ref{table:storm_rolling}, respectively.

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccccl@{}}
    {Parallelism} & {RandomMessageSpout} & {SortBolt} & {CPU Utilisation} & {Memory Usage} \\ \toprule
    1 & {249,143,444} & {249,142,400} & {186.2\%} & {504.3M} \\
    2 & {444,261,351} & {444,259,400} & {352.0\%} & {401.7M} \\
    3 & {350,861,061} & {350,859,800} & {514.7\%} & {382.9M} \\
    4 & {412,429,850} & {412,428,600} & {675.2\%} & {314.2M} \\
    5 & {470,813,184} & {470,811,300} & {835.8\%} & {423.2M} \\
    6 & {498,957,255} & {498,954,600} & {989.6\%} & {235.1M} \\
    7 & {519,744,352} & {519,741,700} & {1,149.0\%} & {637.9M} \\
    8 & {532,285,376} & {532,283,800} & {1,302.9\%} & {618.1M} \\
    9 & {501,519,539} & {501,517,700} & {1,430.4\%} & {579.4M} \\
    10 & {555,468,830} & {555,467,000} & {1,651.6\%} & {564.7M} \\ 
\end{tabular}
\caption{Storm-MC: Tuples processed per component in RollingSort Topology.}
\label{table:storm_mc_rolling}
\end{adjustwidth}
\end{table}

\begin{table}[!htb]
\begin{adjustwidth}{-0.5in}{-0.5in}
\centering
\small
\begin{tabular}{@{}rccccl@{}}
    {Parallelism} & {RandomMessageSpout} & {SortBolt} & {CPU Utilisation} & {Memory Usage} \\ \toprule
    1 & {173,906,935} & {173,900,300} & {267.3\%} & {3.0G} \\
    2 & {226,583,924} & {226,579,200} & {468.3\%} & {3.0G} \\
    3 & {310,949,455} & {310,943,000} & {634.6\%} & {2.9G} \\
    4 & {362,675,336} & {362,663,600} & {815.2\%} & {2.8G} \\
    5 & {409,470,032} & {409,462,100} & {969.4\%} & {2.7G} \\
    6 & {435,471,042} & {435,459,600} & {1,139.6\%} & {2.6G} \\
    7 & {395,386,336} & {395,309,900} & {1,327.7\%} & {2.6G} \\
    8 & {366,680,402} & {366,553,300} & {1,509.1\%} & {2.7G} \\
    9 & {359,091,633} & {358,942,200} & {1,689.5\%} & {2.7G} \\
    10 & {313,912,451} & {313,811,300} & {1,889.5\%} & {2.7G} \\
\end{tabular}
\caption{Apache Storm: Tuples processed per component in RollingSort Topology.}
\label{table:storm_rolling}
\end{adjustwidth}
\end{table}

While Storm-MC still outperforms Apache Storm, the difference in performance is marginal. This is due to the fact that the topology only has two components and the application is mostly memory bound. Storm-MC provides speed improvements for topologies that are mostly CPU-bound and have several components working serially such as WordCount. Furthermore, Storm-MC beats Storm significantly when the parallelism is high, as in previous topologies.

\subsection{Twitter Topology}

The last benchmark that was executed is Twitter topology. It has a \texttt{TwitterSpout} spout generating a group of Twitter hashtags each with a different probability. The hashtags are sent to a \texttt{WordCountBolt}  bolt which counts hashtag frequency, similarly to WordCount topology. The hashtag is then sent along with the current frequency to the \texttt{RankObjects} bolt which keeps the ten most popular hashtags in memory. This bolt sends the ten most popular hashtags to a global \texttt{MergeObjects} bolt at a regular interval (two seconds) which merges results from all \texttt{RankObjects} bolts. The results of running this benchmark on Storm-MC and Apache Storm can be seen in tables \ref{table:storm_mc_twitter} and \ref{table:storm_twitter}, respectively.

\section{Challenges}
\label{sec:challenges}

In this section we are going to discuss challenges we encountered while porting Apache Storm to multi-core machines.

\begin{description}
	\item[Unfamiliarity with Clojure] \hfill \\
	One of the main challenges while working on this project was learning a new programming language - Clojure. Since most of the implementation of Apache Storm is written in Clojure, this language had to be studied and its concepts well understood for us to be able to write code that worked with the existing codebase. By the end of the project writing Clojure became as simple as writing Java.
	\item[Lack of Documentation] \hfill \\
	Even though Apache Storm is a popular project documentation is available only for the high level concepts used within Storm. The implementation details are often obscured away in hard to understand functions. Since the documentation is lacking our knowledge of Storm had to be obtained by reading the source code of an initially unfamiliar language.
\end{description}

